#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fanren ER Extractor Demo Test
ç®€å•çš„é›†æˆæµ‹è¯•è„šæœ¬ï¼Œç›´è§‚å±•ç¤ºå®ä½“æå–æ•ˆæœ
"""

import asyncio
import logging
import sys
import os

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from imod.fanren_er_extract_mod import FanrenEntityExtractor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def create_test_text():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„æ–‡æœ¬æ•°æ®"""
    test_content = """
    éŸ©ç«‹åœ¨ä¸ƒç„é—¨ä¸­é‡åˆ°äº†è‡ªå·±çš„ç¬¬ä¸€ä¸ªå¸ˆå‚…å¢¨å¤§å¤«ï¼Œå¢¨å¤§å¤«ä¼ æˆäº†ä»–é•¿æ˜¥åŠŸï¼Œå¸®åŠ©ä»–è¸ä¸Šäº†ä¿®ä»™ä¹‹è·¯ã€‚
    åæ¥éŸ©ç«‹åŠ å…¥äº†é»„æ«è°·ï¼Œåœ¨é‚£é‡Œä»–ä¿®ç‚¼äº†é’å…ƒå‰‘è¯€ï¼Œå¹¶è·å¾—äº†æŒå¤©ç“¶è¿™ä¸ªç¥ç§˜çš„æ³•å®ã€‚
    åœ¨é»„æ«è°·ä¸­ï¼ŒéŸ©ç«‹è¿˜è®¤è¯†äº†å¸ˆå§æŸ³ç‰ï¼Œä¸¤äººä¸€èµ·å‚åŠ äº†å®—é—¨çš„è¯•ç‚¼ã€‚
    éŸ©ç«‹å‡­å€ŸæŒå¤©ç“¶çš„èƒ½åŠ›ï¼Œåœ¨ä¿®ç‚¼æ–¹é¢è¿›æ­¥ç¥é€Ÿï¼Œå¾ˆå¿«æˆä¸ºäº†å†…é—¨å¼Ÿå­ã€‚
    """

    return test_content


async def test_single_text_extraction():
    """æµ‹è¯•å•ä¸ªæ–‡æœ¬å—çš„å®ä½“æå–"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å•ä¸ªæ–‡æœ¬å—å®ä½“æå–...")

    try:
        # åˆ›å»ºæå–å™¨å®ä¾‹
        extractor = FanrenEntityExtractor()

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        text_content = create_test_text()

        logger.info(f"ğŸ“ å†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
        logger.info("ğŸ“„ åŸæ–‡å†…å®¹:")
        logger.info("-" * 50)
        logger.info(text_content.strip())
        logger.info("-" * 50)

        # æ‰§è¡Œå®ä½“æå–
        result = await extractor.extract_entities_and_relations(text_content)

        # æ˜¾ç¤ºæå–ç»“æœ
        logger.info("âœ… å®ä½“æå–å®Œæˆ!")
        logger.info(f"ğŸ¯ æå–åˆ° {len(result.entities)} ä¸ªå®ä½“")
        logger.info(f"ğŸ”— æå–åˆ° {len(result.relationships)} ä¸ªå…³ç³»")

        # è¯¦ç»†æ˜¾ç¤ºå®ä½“
        if result.entities:
            logger.info("\nğŸ“‹ å®ä½“åˆ—è¡¨:")
            for i, entity in enumerate(result.entities, 1):
                logger.info(f"{i}. {entity.name} [{entity.category}]")
                logger.info(f"   æè¿°: {entity.desc}")

        # è¯¦ç»†æ˜¾ç¤ºå…³ç³»
        if result.relationships:
            logger.info("\nğŸ”— å…³ç³»åˆ—è¡¨:")
            for i, relation in enumerate(result.relationships, 1):
                logger.info(f"{i}. {relation.source} â†’ {relation.target}")
                logger.info(f"   å…³ç³»: {relation.desc}")

        return result

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return None


async def test_batch_extraction():
    """æµ‹è¯•æ‰¹é‡æ–‡æœ¬å—çš„å®ä½“æå–"""
    logger.info("\nğŸš€ å¼€å§‹æµ‹è¯•æ‰¹é‡æ–‡æœ¬å—å®ä½“æå–...")

    try:
        # åˆ›å»ºæå–å™¨å®ä¾‹
        extractor = FanrenEntityExtractor()

        # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æœ¬å—
        text_chunks = []

        # æ–‡æœ¬å—1
        content1 = "éŸ©ç«‹åœ¨ä¸ƒç„é—¨é‡åˆ°äº†å¢¨å¤§å¤«ï¼Œå­¦ä¹ äº†é•¿æ˜¥åŠŸã€‚å¢¨å¤§å¤«æ˜¯éŸ©ç«‹çš„ç¬¬ä¸€ä¸ªå¸ˆå‚…ã€‚"
        text_chunks.append(content1)

        # æ–‡æœ¬å—2
        content2 = "éŸ©ç«‹åæ¥åŠ å…¥äº†é»„æ«è°·ï¼Œåœ¨é‚£é‡Œä¿®ç‚¼äº†é’å…ƒå‰‘è¯€ã€‚ä»–è¿˜è·å¾—äº†æŒå¤©ç“¶è¿™ä¸ªç¥ç§˜æ³•å®ã€‚"
        text_chunks.append(content2)

        logger.info(f"ğŸ“š å‡†å¤‡å¤„ç† {len(text_chunks)} ä¸ªæ–‡æœ¬å—")

        # æ‰§è¡Œæ‰¹é‡æå–
        results = await extractor.extract_from_chunks_batch(text_chunks)

        # æ˜¾ç¤ºæ‰¹é‡æå–ç»“æœ
        logger.info("âœ… æ‰¹é‡æå–å®Œæˆ!")

        total_entities = sum(len(result.entities) for result in results)
        total_relationships = sum(len(result.relationships) for result in results)

        logger.info(f"ğŸ¯ æ€»è®¡æå–åˆ° {total_entities} ä¸ªå®ä½“")
        logger.info(f"ğŸ”— æ€»è®¡æå–åˆ° {total_relationships} ä¸ªå…³ç³»")

        # åˆ†å—æ˜¾ç¤ºç»“æœ
        for i, (text_chunk, result) in enumerate(zip(text_chunks, results), 1):
            logger.info(f"\nğŸ“– æ–‡æœ¬å— {i}")
            logger.info(f"   å®ä½“æ•°: {len(result.entities)}, å…³ç³»æ•°: {len(result.relationships)}")

            if result.entities:
                logger.info("   å®ä½“: " + ", ".join([f"{e.name}[{e.category}]" for e in result.entities]))
            if result.relationships:
                logger.info("   å…³ç³»: " + ", ".join([f"{r.source}â†’{r.target}" for r in result.relationships]))

        return results

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")
        return None


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ§ª å‡¡äººå®ä½“å…³ç³»æå–å™¨ - é›†æˆæµ‹è¯•å¼€å§‹")
    logger.info("=" * 60)

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env = ["MINIMAX_OPENAI_API_KEY", "MINIMAX_OPENAI_BASE_URL", "MINIMAX_OPENAI_MODEL"]
    missing_env = [env for env in required_env if not os.getenv(env)]

    if missing_env:
        logger.error(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_env)}")
        logger.error("è¯·ç¡®ä¿å·²é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        for env in missing_env:
            logger.error(f"  - {env}")
        return

    logger.info("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")

    # æ‰§è¡Œæµ‹è¯•
    try:
        # æµ‹è¯•1: å•ä¸ªæ–‡æœ¬å—
        result1 = await test_single_text_extraction()

        # æµ‹è¯•2: æ‰¹é‡å¤„ç†
        result2 = await test_batch_extraction()

        # æ€»ç»“
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ é›†æˆæµ‹è¯•å®Œæˆ!")

        if result1 and result2:
            logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        else:
            logger.info("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())